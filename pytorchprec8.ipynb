{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorchprec8.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMjsQkNXRyj9e1s9GO1eS1s"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SYeyp_Plf7e"
      },
      "source": [
        "# Perceptron (8-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfk-coeyltBj",
        "outputId": "79733888-1df6-48d4-a171-65efd5fd3c4b"
      },
      "source": [
        "# XOR Perceptron Code\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
        "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
        "\n",
        "# nn Layers\n",
        "linear = torch.nn.Linear(2,1,bias=True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "# model\n",
        "model = torch.nn.Sequential(linear,sigmoid).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr=1)\n",
        "\n",
        "for step in range(10001):\n",
        "  optimizer.zero_grad()\n",
        "  hypothesis = model(X)\n",
        "\n",
        "  # cost/loss function\n",
        "  cost = criterion(hypothesis,Y)\n",
        "  cost.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if step % 1000 == 0:\n",
        "    print(step, cost.item())\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis>0.5 else False\n",
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.7273974418640137\n",
            "1000 0.6931471824645996\n",
            "2000 0.6931471824645996\n",
            "3000 0.6931471824645996\n",
            "4000 0.6931471824645996\n",
            "5000 0.6931471824645996\n",
            "6000 0.6931471824645996\n",
            "7000 0.6931471824645996\n",
            "8000 0.6931471824645996\n",
            "9000 0.6931471824645996\n",
            "10000 0.6931471824645996\n",
            "\n",
            "Hypothesis:  [[0.5]\n",
            " [0.5]\n",
            " [0.5]\n",
            " [0.5]] \n",
            "Correct:  [[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]] \n",
            "Accuracy:  0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALcnoWjFn8L_"
      },
      "source": [
        "# Multi Layer Perceptron (8-2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mj4SvGqE3M2G",
        "outputId": "e88cdcdf-f5de-4c0d-a05b-ccda395612b4"
      },
      "source": [
        "# Back Propagation 1\n",
        "X = torch.FloatTensor([[0,0],[0,1],[1,0],[1,1]]).to(device)\n",
        "Y = torch.FloatTensor([[0],[1],[1],[0]]).to(device)\n",
        "learning_rate = 1\n",
        "# nn Layers\n",
        "w1 = torch.nn.Parameter(torch.Tensor(2, 2)).to(device)\n",
        "b1 = torch.nn.Parameter(torch.Tensor(2)).to(device)\n",
        "w2 = torch.nn.Parameter(torch.Tensor(2, 1)).to(device)\n",
        "b2 = torch.nn.Parameter(torch.Tensor(1)).to(device)\n",
        "torch.nn.init.normal_(w1)\n",
        "torch.nn.init.normal_(b1)\n",
        "torch.nn.init.normal_(w2)\n",
        "torch.nn.init.normal_(b2)\n",
        "def sigmoid(x):\n",
        "    #  sigmoid function\n",
        "    return 1.0 / (1.0 + torch.exp(-x))\n",
        "    # return torch.div(torch.tensor(1), torch.add(torch.tensor(1.0), torch.exp(-x)))\n",
        "def sigmoid_prime(x):\n",
        "    # derivative of the sigmoid function\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "for step in range(10001):\n",
        "  # forward\n",
        "  l1 = torch.add(torch.matmul(X, w1), b1)\n",
        "  a1 = sigmoid(l1)\n",
        "  l2 = torch.add(torch.matmul(a1, w2), b2)\n",
        "  Y_pred = sigmoid(l2)\n",
        "  cost = -torch.mean(Y*torch.log(Y_pred)+(1-Y)*torch.log(1-Y_pred))\n",
        "  # back prop (chain rule)\n",
        "  # Loss derivative\n",
        "  d_Y_pred = (Y_pred-Y)/(Y_pred*(1.0-Y_pred)+1e-7)\n",
        "  # Layer 2\n",
        "  d_l2 = d_Y_pred * sigmoid_prime(l2)\n",
        "  d_b2 = d_l2\n",
        "  d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_l2)\n",
        "  # Layer 1\n",
        "  d_a1 = torch.matmul(d_l2, torch.transpose(w2, 0, 1))\n",
        "  d_l1 = d_a1 * sigmoid_prime(l1)\n",
        "  d_b1 = d_l1\n",
        "  d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_l1)\n",
        "  # weight update\n",
        "  w1 = w1 - learning_rate * d_w1\n",
        "  b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
        "  w2 = w2 - learning_rate * d_w2\n",
        "  b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
        "  if step % 1000 == 0:\n",
        "    print(step, cost.item())\n",
        "\n",
        "  # Accuracy computation\n",
        "# True if hypothesis>0.5 else False\n",
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.9865847826004028\n",
            "1000 0.015030864626169205\n",
            "2000 0.006420612335205078\n",
            "3000 0.004071197006851435\n",
            "4000 0.0029783749487251043\n",
            "5000 0.0023473412729799747\n",
            "6000 0.001936615677550435\n",
            "7000 0.001648081000894308\n",
            "8000 0.0014342383947223425\n",
            "9000 0.0012694606557488441\n",
            "10000 0.001138653140515089\n",
            "\n",
            "Hypothesis:  [[1.1168801e-04]\n",
            " [9.9982882e-01]\n",
            " [9.9984229e-01]\n",
            " [1.8529482e-04]] \n",
            "Correct:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NosdNsgGoUjf",
        "outputId": "d9290245-4ca7-4f6d-a064-44d129bc010d"
      },
      "source": [
        "# Back Propagation 2\n",
        "\n",
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "# parameters\n",
        "learning_rate = 0.5\n",
        "batch_size = 10\n",
        "\n",
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)\n",
        "\n",
        "# dataset loader\n",
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=True,\n",
        "                                          drop_last=True)\n",
        "\n",
        "w1 = torch.nn.Parameter(torch.Tensor(784, 30)).to(device)\n",
        "b1 = torch.nn.Parameter(torch.Tensor(30)).to(device)\n",
        "w2 = torch.nn.Parameter(torch.Tensor(30, 10)).to(device)\n",
        "b2 = torch.nn.Parameter(torch.Tensor(10)).to(device)\n",
        "\n",
        "torch.nn.init.normal_(w1)\n",
        "torch.nn.init.normal_(b1)\n",
        "torch.nn.init.normal_(w2)\n",
        "torch.nn.init.normal_(b2)\n",
        "\n",
        "def sigmoid(x):\n",
        "    #  sigmoid function\n",
        "    return 1.0 / (1.0 + torch.exp(-x))\n",
        "    # return torch.div(torch.tensor(1), torch.add(torch.tensor(1.0), torch.exp(-x)))\n",
        "\n",
        "def sigmoid_prime(x):\n",
        "    # derivative of the sigmoid function\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)[:1000]\n",
        "Y_test = mnist_test.test_labels.to(device)[:1000]\n",
        "i = 0\n",
        "while not i == 10000:\n",
        "    for X, Y in data_loader:\n",
        "        i += 1\n",
        "\n",
        "        # forward\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = torch.zeros((batch_size, 10)).scatter_(1, Y.unsqueeze(1), 1).to(device)    # one-hot\n",
        "        l1 = torch.add(torch.matmul(X, w1), b1)\n",
        "        a1 = sigmoid(l1)\n",
        "        l2 = torch.add(torch.matmul(a1, w2), b2)\n",
        "        y_pred = sigmoid(l2)\n",
        "\n",
        "        diff = y_pred - Y\n",
        "\n",
        "        # Back prop (chain rule)\n",
        "        d_l2 = diff * sigmoid_prime(l2)\n",
        "        d_b2 = d_l2\n",
        "        d_w2 = torch.matmul(torch.transpose(a1, 0, 1), d_l2)\n",
        "\n",
        "        d_a1 = torch.matmul(d_l2, torch.transpose(w2, 0, 1))\n",
        "        d_l1 = d_a1 * sigmoid_prime(l1)\n",
        "        d_b1 = d_l1\n",
        "        d_w1 = torch.matmul(torch.transpose(X, 0, 1), d_l1)\n",
        "\n",
        "        w1 = w1 - learning_rate * d_w1\n",
        "        b1 = b1 - learning_rate * torch.mean(d_b1, 0)\n",
        "        w2 = w2 - learning_rate * d_w2\n",
        "        b2 = b2 - learning_rate * torch.mean(d_b2, 0)\n",
        "\n",
        "        if i % 1000 == 0:\n",
        "            l1 = torch.add(torch.matmul(X_test, w1), b1)\n",
        "            a1 = sigmoid(l1)\n",
        "            l2 = torch.add(torch.matmul(a1, w2), b2)\n",
        "            y_pred = sigmoid(l2)\n",
        "            acct_mat = torch.argmax(y_pred, 1) == Y_test\n",
        "            acct_res = acct_mat.sum()\n",
        "            print(acct_res.item())\n",
        "\n",
        "        if i == 10000:\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:69: UserWarning: test_data has been renamed data\n",
            "  warnings.warn(\"test_data has been renamed data\")\n",
            "/usr/local/lib/python3.7/dist-packages/torchvision/datasets/mnist.py:59: UserWarning: test_labels has been renamed targets\n",
            "  warnings.warn(\"test_labels has been renamed targets\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "749\n",
            "776\n",
            "871\n",
            "889\n",
            "887\n",
            "903\n",
            "895\n",
            "913\n",
            "907\n",
            "904\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUZdwMn-tcLy",
        "outputId": "d66e9ece-f999-48b5-e74b-fb60bc19ceb0"
      },
      "source": [
        "# xor-nn\n",
        "\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
        "\n",
        "# nn layers\n",
        "linear1 = torch.nn.Linear(2, 2, bias=True)\n",
        "linear2 = torch.nn.Linear(2, 1, bias=True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "# model\n",
        "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1\n",
        "\n",
        "for step in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # cost/loss function\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 1000 == 0:\n",
        "        print(step, cost.item())\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis>0.5 else False\n",
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.7434073090553284\n",
            "1000 0.6930999755859375\n",
            "2000 0.6838315725326538\n",
            "3000 0.013983809389173985\n",
            "4000 0.005768344737589359\n",
            "5000 0.0036007347516715527\n",
            "6000 0.0026096487417817116\n",
            "7000 0.00204361486248672\n",
            "8000 0.001678097527474165\n",
            "9000 0.0014228165382519364\n",
            "10000 0.0012345188297331333\n",
            "\n",
            "Hypothesis:  [[0.00106364]\n",
            " [0.99889404]\n",
            " [0.99889404]\n",
            " [0.00165861]] \n",
            "Correct:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlKLekfOuYX9",
        "outputId": "53a52551-5466-4ab5-98a9-7160d29ccc2d"
      },
      "source": [
        "# xor-nn-wide-deep\n",
        "\n",
        "import torch\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "# for reproducibility\n",
        "torch.manual_seed(777)\n",
        "if device == 'cuda':\n",
        "    torch.cuda.manual_seed_all(777)\n",
        "\n",
        "X = torch.FloatTensor([[0, 0], [0, 1], [1, 0], [1, 1]]).to(device)\n",
        "Y = torch.FloatTensor([[0], [1], [1], [0]]).to(device)\n",
        "\n",
        "# nn layers\n",
        "linear1 = torch.nn.Linear(2, 10, bias=True)\n",
        "linear2 = torch.nn.Linear(10, 10, bias=True)\n",
        "linear3 = torch.nn.Linear(10, 10, bias=True)\n",
        "linear4 = torch.nn.Linear(10, 1, bias=True)\n",
        "sigmoid = torch.nn.Sigmoid()\n",
        "\n",
        "# model\n",
        "model = torch.nn.Sequential(linear1, sigmoid, linear2, sigmoid, linear3, sigmoid, linear4, sigmoid).to(device)\n",
        "\n",
        "# define cost/loss & optimizer\n",
        "criterion = torch.nn.BCELoss().to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1)  # modified learning rate from 0.1 to 1\n",
        "\n",
        "for step in range(10001):\n",
        "    optimizer.zero_grad()\n",
        "    hypothesis = model(X)\n",
        "\n",
        "    # cost/loss function\n",
        "    cost = criterion(hypothesis, Y)\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 1000 == 0:\n",
        "        print(step, cost.item())\n",
        "\n",
        "# Accuracy computation\n",
        "# True if hypothesis>0.5 else False\n",
        "with torch.no_grad():\n",
        "    hypothesis = model(X)\n",
        "    predicted = (hypothesis > 0.5).float()\n",
        "    accuracy = (predicted == Y).float().mean()\n",
        "    print('\\nHypothesis: ', hypothesis.detach().cpu().numpy(), '\\nCorrect: ', predicted.detach().cpu().numpy(), '\\nAccuracy: ', accuracy.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 0.6948983669281006\n",
            "1000 0.6931379437446594\n",
            "2000 0.6931172013282776\n",
            "3000 0.6930762529373169\n",
            "4000 0.6929103136062622\n",
            "5000 0.6820822358131409\n",
            "6000 0.0013032691786065698\n",
            "7000 0.0004838125314563513\n",
            "8000 0.00028903622296638787\n",
            "9000 0.0002038097009062767\n",
            "10000 0.00015648972475901246\n",
            "\n",
            "Hypothesis:  [[1.1168801e-04]\n",
            " [9.9982882e-01]\n",
            " [9.9984229e-01]\n",
            " [1.8529482e-04]] \n",
            "Correct:  [[0.]\n",
            " [1.]\n",
            " [1.]\n",
            " [0.]] \n",
            "Accuracy:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vVXDtf3pv217"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}